{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "1f2ce10b-f139-4f55-8d4a-8d88b6651b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/tensor/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.5646 - loss: 39.9752 - val_accuracy: 0.2381 - val_loss: 11.7979\n",
      "Epoch 2/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5396 - loss: 6.6786 - val_accuracy: 0.7619 - val_loss: 2.3776\n",
      "Epoch 3/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.5177 - loss: 3.6081 - val_accuracy: 0.4762 - val_loss: 0.9126\n",
      "Epoch 4/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6438 - loss: 1.2807 - val_accuracy: 0.2381 - val_loss: 1.9804\n",
      "Epoch 5/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6115 - loss: 0.7549 - val_accuracy: 0.9524 - val_loss: 0.3340\n",
      "Epoch 6/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.8760 - loss: 0.2726 - val_accuracy: 0.9524 - val_loss: 0.3159\n",
      "Epoch 7/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9500 - loss: 0.2145 - val_accuracy: 0.9524 - val_loss: 0.3743\n",
      "Epoch 8/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9750 - loss: 0.1420 - val_accuracy: 0.9524 - val_loss: 0.3014\n",
      "Epoch 9/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0698 - val_accuracy: 0.9524 - val_loss: 0.3468\n",
      "Epoch 10/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.0329 - val_accuracy: 0.9524 - val_loss: 0.3815\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9524 - loss: 0.3815\n",
      "Loss: 0.38148385286331177, Accuracy: 0.9523809552192688\n",
      "INFO:tensorflow:Assets written to: HTMLConvolutional/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: HTMLConvolutional/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'HTMLConvolutional'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 48, 48, 1), dtype=tf.float32, name='keras_tensor_470')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 2), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  14892226448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  14892227984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  14892227792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  14892228752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  14892228560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  14892229520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  14892229328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  14892230288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  14892230096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  14892231056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from requests.exceptions import RequestException\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "from collections import Counter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from tensorflow import keras\n",
    "from keras import layers, models\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import tensorflow as tf\n",
    "\n",
    "# Scrape configuration\n",
    "MAX_PAGES = 1\n",
    "START_URL = \"https://www.nytimes.com/timeswire\"  # Replace with a seed URL\n",
    "IMAGE_SIZE = (48, 48)\n",
    "CONTRAST_THRESHOLD = 4.5\n",
    "OUTPUT_DIR = \"scraped_images\"\n",
    "SCREENSHOT_PATH = \"full_page_screenshot.png\"\n",
    "FINAL_SCREENSHOT_PATH = \"final_screenshot.png\"\n",
    "chrome_driver_path = '/opt/homebrew/bin/chromedriver'\n",
    "targetElements = ['h1', 'h3']\n",
    "\n",
    "class CustomModel:\n",
    "    def __init__(self, model=None):\n",
    "        self.model = model\n",
    "        self.driver = self._initialize_webdriver()\n",
    "        self.css_selector_map = {}\n",
    "        self.X = []\n",
    "        self.y = []\n",
    "\n",
    "    def _initialize_webdriver(self):\n",
    "        chrome_options = Options()\n",
    "        chrome_options.add_argument(\"--headless\")\n",
    "        chrome_options.add_argument(\"--no-sandbox\")\n",
    "        chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "        driver = webdriver.Chrome(service=Service(chrome_driver_path), options=chrome_options)\n",
    "        \n",
    "        return driver\n",
    "\n",
    "    def get_css_selector(self, element):\n",
    "        \"\"\"Generates a unique CSS selector for a given HTML element.\"\"\"\n",
    "        selector = element.name\n",
    "        if element.get('id'):\n",
    "            selector += f'#{element[\"id\"]}'\n",
    "        if element.get('class'):\n",
    "            selector += '.' + '.'.join(element[\"class\"])\n",
    "        for attribute, value in element.attrs.items():\n",
    "            if attribute not in ['id', 'class']:\n",
    "                selector += f'[{attribute}=\"{value}\"]'\n",
    "        return selector\n",
    "\n",
    "    def calculate_contrast(self, image):\n",
    "        \"\"\"Calculate contrast ratio using WCAG guidelines.\"\"\"\n",
    "        grayscale_image = image.convert('L')\n",
    "        pixel_values = np.array(grayscale_image)\n",
    "        min_intensity = pixel_values.min()\n",
    "        max_intensity = pixel_values.max()\n",
    "        \n",
    "        l1 = (max_intensity + 0.05) / 255\n",
    "        l2 = (min_intensity + 0.05) / 255\n",
    "        contrast_ratio = (l1 + 0.05) / (l2 + 0.05) if l1 > l2 else (l2 + 0.05) / (l1 + 0.05)\n",
    "        \n",
    "        return contrast_ratio\n",
    "\n",
    "    def scrape_links(self, url, visited, max_pages=MAX_PAGES):\n",
    "        \"\"\"Crawl the web starting from a URL, returning a list of links.\"\"\"\n",
    "        to_visit = [url]\n",
    "        links = []\n",
    "        while to_visit and len(links) < max_pages:\n",
    "            current_url = to_visit.pop(0)\n",
    "            if current_url in visited:\n",
    "                continue\n",
    "            try:\n",
    "                response = requests.get(url, timeout=3)\n",
    "                if response.status_code == 200:\n",
    "                    soup = BeautifulSoup(self.driver.page_source, \"html.parser\")\n",
    "                    visited.add(current_url)\n",
    "                    links.append(current_url)\n",
    "                    # Add new links to the queue\n",
    "                    for anchor in soup.find_all(\"a\", href=True):\n",
    "                        href = anchor[\"href\"]\n",
    "                        if href.startswith(\"http\"):\n",
    "                            to_visit.append(href)\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to process {current_url}: {e}\")\n",
    "        return links[:max_pages]\n",
    "\n",
    "    def screenshot_element(self, element):    \n",
    "        \"\"\"Takes a screenshot of the target element and saves it.\"\"\"\n",
    "        element_location = element.location\n",
    "        element_size = element.size\n",
    "        screenshot = Image.open(SCREENSHOT_PATH)\n",
    "        screenshot_width, screenshot_height = screenshot.size\n",
    "        \n",
    "        element_left = element_location['x']\n",
    "        element_top = element_location['y']\n",
    "        element_right = min(screenshot_width, element_left + element_size['width']) \n",
    "        element_bottom = min(element_top + element_size['height'], screenshot_height)\n",
    "        \n",
    "        # Crop the image using Pillow\n",
    "        cropped_image = screenshot.crop((element_left, element_top, element_right, element_bottom))\n",
    "\n",
    "        if not os.path.exists(OUTPUT_DIR):\n",
    "            os.makedirs(OUTPUT_DIR)\n",
    "        \n",
    "        element_screenshot_path = os.path.join(OUTPUT_DIR, f\"screenshot_{random.randint(1, 1000000)}.png\")\n",
    "        cropped_image.save(element_screenshot_path)\n",
    "        return element_screenshot_path\n",
    "\n",
    "    def preprocess_image(self, image_path):\n",
    "        \"\"\"Resize and preprocess image for CNN.\"\"\"\n",
    "        image = Image.open(image_path).convert('L')\n",
    "        image = image.resize((48, 48))\n",
    "        return np.array(image)\n",
    "\n",
    "    def fetch_html(self, url):\n",
    "        \"\"\"Fetch the HTML of a webpage.\"\"\"\n",
    "        try:\n",
    "            self.driver.get(url)\n",
    "            time.sleep(3)\n",
    "            response = requests.get(url, timeout=3)\n",
    "            response.raise_for_status()  # Will raise an exception for HTTP errors\n",
    "            return self.driver.page_source\n",
    "        except RequestException as e:\n",
    "            print(f\"Error fetching {url}: {e}\")\n",
    "\n",
    "    def scrape_and_process_data(self):\n",
    "        \"\"\"Scrape and process data into X and y.\"\"\"\n",
    "        visited_urls = set()\n",
    "        scraped_links = self.scrape_links(START_URL, visited_urls)\n",
    "\n",
    "        for link in scraped_links:\n",
    "            try:\n",
    "                html_content = self.fetch_html(link)\n",
    "                if html_content:\n",
    "                    soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "\n",
    "                    # Set window size to current width, and max height\n",
    "                    window_size = self.driver.get_window_size()                            \n",
    "                    full_page_height = self.driver.execute_script(\"return document.documentElement.scrollHeight;\") \n",
    "                    self.driver.set_window_size(window_size['width'],full_page_height)\n",
    "                    self.driver.save_screenshot(SCREENSHOT_PATH) \n",
    "                    \n",
    "                    screenshot = Image.open(SCREENSHOT_PATH)\n",
    "                    screenshot_width, screenshot_height = screenshot.size\n",
    "                    \n",
    "                    ratio = screenshot_width / screenshot_height    \n",
    "                    screenshot = screenshot.resize((window_size['width'], int(window_size['width'] / ratio)))\n",
    "                    screenshot.save(SCREENSHOT_PATH)\n",
    "\n",
    "                    # Extract target elements from body\n",
    "                    for element in soup.find('body').find_all(targetElements):\n",
    "                        text = element.get_text(strip=True)\n",
    "                        if text:\n",
    "                            try:\n",
    "                                css_selector = self.get_css_selector(element)\n",
    "                                driverElements = self.driver.find_elements(By.CSS_SELECTOR, css_selector)\n",
    "\n",
    "                                if driverElements:\n",
    "                                    for driverElement in driverElements:                               \n",
    "                                        screenshot_path = self.screenshot_element(driverElement)\n",
    "                                        image = self.preprocess_image(screenshot_path)                        \n",
    "                                        contrast_ratio = self.calculate_contrast(Image.fromarray(image.squeeze()))\n",
    "                                        self.X.append(image)\n",
    "                                        self.y.append(1 if contrast_ratio >= CONTRAST_THRESHOLD else 0)\n",
    "                                        self.css_selector_map[len(self.X) - 1] = css_selector\n",
    "                            except Exception as e:\n",
    "                                print(f\"Error processing element with selector {css_selector}: {e}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {link}: {e}\")\n",
    "\n",
    "        self.X = np.array(self.X)\n",
    "        self.y = np.array(self.y)\n",
    "\n",
    "    def train_model(self):\n",
    "        \"\"\"Train the CNN model.\"\"\"\n",
    "        X_train, X_test, y_train, y_test = train_test_split(self.X, self.y, test_size=0.2, random_state=42)\n",
    "        smote = SMOTE(sampling_strategy='auto', k_neighbors=3)\n",
    "        X_flattened = X_train.reshape(X_train.shape[0], -1)\n",
    "        X_resampled, y_resampled = smote.fit_resample(X_flattened, y_train)  \n",
    "        X_shaped = X_resampled.reshape(X_resampled.shape[0], *IMAGE_SIZE, 1)\n",
    "\n",
    "        self.model = models.Sequential([\n",
    "            layers.Conv2D(32, (3, 3), activation='relu', input_shape=(*IMAGE_SIZE, 1)),\n",
    "            layers.MaxPooling2D((2, 2)),\n",
    "            layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "            layers.MaxPooling2D((2, 2)),\n",
    "            layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "            layers.MaxPooling2D((2, 2)),\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(128, activation='relu'),\n",
    "            layers.Dense(2, activation='softmax')\n",
    "        ])\n",
    "\n",
    "        self.model.compile(optimizer='adam',\n",
    "                           loss='sparse_categorical_crossentropy',\n",
    "                           metrics=['accuracy'])\n",
    "\n",
    "        self.model.fit(X_shaped, y_resampled, epochs=10, validation_data=(X_test, y_test))\n",
    "        loss, accuracy = self.model.evaluate(X_test, y_test)\n",
    "        print(f\"Loss: {loss}, Accuracy: {accuracy}\")\n",
    "\n",
    "    @tf.function(input_signature=[tf.TensorSpec(shape=[None, 48, 48, 1], dtype=tf.float32)])\n",
    "    def custom_infer(self, elements): \n",
    "        predictions = self.model(elements)\n",
    "        predicted_classes = tf.argmax(predictions, axis=1)\n",
    "        prediction_results = []\n",
    "\n",
    "        for idx, prediction in enumerate(predictions):\n",
    "            css_selector = self.css_selector_map.get(idx)\n",
    "            if css_selector:\n",
    "                prediction_results.append({\n",
    "                    \"css_selector\": css_selector,\n",
    "                    \"prediction\": int(predicted_classes[idx])\n",
    "                })\n",
    "                if int(predicted_clases[idx]) == 0:  # Low contrast\n",
    "                    self.driver.execute_script(\n",
    "                        \"arguments[0].style.border = '3px solid red';\",\n",
    "                        self.driver.find_element(By.CSS_SELECTOR, css_selector)\n",
    "                    )\n",
    "        self.driver.save_screenshot(FINAL_SCREENSHOT_PATH)\n",
    "        return prediction_results\n",
    "\n",
    "    def __call__(self, elements):\n",
    "        \"\"\"Override the __call__ method to run custom inference.\"\"\"\n",
    "        return self.custom_infer(elements)\n",
    "\n",
    "    def close_driver(self):\n",
    "        \"\"\"Close the web driver after processing.\"\"\"\n",
    "        self.driver.quit()\n",
    "\n",
    "    def export_model(self, path):\n",
    "        \"\"\"Export the trained model to a file.\"\"\"\n",
    "        self.model.export(path)\n",
    "\n",
    "# Usage Example:\n",
    "custom_model = CustomModel()\n",
    "custom_model.scrape_and_process_data()\n",
    "custom_model.train_model()\n",
    "custom_model.export_model(\"HTMLConvolutional\")\n",
    "custom_model.close_driver()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01cc7de-8693-4dac-a0d7-7523d410272a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
